{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SET FLAGS SO YOU DON'T OVERWRITE EXISTING FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF YOU'RE DOING THIS FOR SELECT FILMS, INPUT THE DATE RANGE FOR WHICH YOU WANT RELEASE DATE BASED FEATURES TO BE COMPUTED OVER, FOR EACH FILM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SELECT_FILMS = True\n",
    "SELECT_TITLES = ['Rue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# STRUCTURE: {TITLE: [EARLIEST DATE, LATEST DATE]} WITH DATES IN 'YYYY-MM-DD' FORMAT\n",
    "SELECT_DATES = {'Rue': ['2019-01-01', '2019-12-31']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import json\n",
    "import networkx as nx\n",
    "from networkx import *\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "\n",
    "# function to flatten the titles dict\n",
    "def flatten(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull in titles and people json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "titles = []\n",
    "with open(os.path.dirname(os.getcwd()) + '/titles.json') as f:\n",
    "    for line in f:\n",
    "        while True:\n",
    "            try:\n",
    "                titles.append(json.loads(line))\n",
    "                break\n",
    "            except ValueError:\n",
    "                # Not yet a complete JSON value\n",
    "                line += next(f)\n",
    "\n",
    "people = []\n",
    "with open(os.path.dirname(os.getcwd()) + '/people.json') as f:\n",
    "    for line in f:\n",
    "        while True:\n",
    "            try:\n",
    "                people.append(json.loads(line))\n",
    "                break\n",
    "            except ValueError:\n",
    "                # Not yet a complete JSON value\n",
    "                line += next(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "franchises = []\n",
    "with open(os.path.dirname(os.getcwd()) + '/franchises.json') as f:  \n",
    "    for line in f:\n",
    "        franchises.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a dictionary of films from titles list\n",
    "titles_dict = {}\n",
    "for title in titles:\n",
    "    name = title['title']\n",
    "    titles_dict[name] = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary of people from person list\n",
    "people_dict = {}\n",
    "for person in people:\n",
    "    name = person['name']\n",
    "    people_dict[name] = person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a franchise dataframe\n",
    "franchise_dicts = []\n",
    "for franchise in franchises:\n",
    "    for film in franchise['films']:\n",
    "        franchise_dict = {}\n",
    "        franchise_dict['franchise'] = franchise['franchise']\n",
    "        franchise_dict['film'] = film\n",
    "        franchise_dicts.append(franchise_dict)\n",
    "        \n",
    "franchise_df = pd.DataFrame(franchise_dicts)\n",
    "for i in range(len(franchise_df)):\n",
    "    film = franchise_df['film'].iat[i]\n",
    "    if film not in titles_dict:\n",
    "        continue\n",
    "    try:\n",
    "        week_1_gross = titles_dict[film]['week_1_gross']\n",
    "        week_1_gross = int(week_1_gross)\n",
    "    except:\n",
    "        week_1_gross = np.nan\n",
    "    franchise_df.at[i, 'week_1_gross'] = week_1_gross\n",
    "    franchise_df.at[i, 'first_wknd_gross'] = titles_dict[film]['first_wknd_gross']\n",
    "    franchise_df.at[i, 'domestic_gross'] = titles_dict[film]['domestic_gross']\n",
    "    franchise_df.at[i, 'release_date'] = pd.to_datetime(titles_dict[film]['theatrical_release']['$date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alanxie/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create dicts to hold actor and director scores, grosses, and tenures of titles\n",
    "# These are calculated by taking their mean scores across the films they were in / directed.\n",
    "\n",
    "actors = {}\n",
    "directors = {}\n",
    "\n",
    "for person in people:\n",
    "    try:\n",
    "        if 'production_co' not in person['profession'] and 'distribution_co' not in person['profession']:\n",
    "            gross_temp = 0\n",
    "            tenure = 0\n",
    "            name = person['name']\n",
    "            dates = []\n",
    "            for film in person['films']:\n",
    "                if film in titles_dict and pd.notnull(titles_dict[film]['domestic_gross']):\n",
    "                    gross_temp += titles_dict[film]['domestic_gross']\n",
    "                if titles_dict[film]['theatrical_release'] == None:\n",
    "                    continue\n",
    "                else:\n",
    "                    dates.append(pd.to_datetime(titles_dict[film]['theatrical_release']['$date']))\n",
    "            if len(dates) > 0:\n",
    "                dates = np.array(dates)\n",
    "                tenure = max(dates) - min(dates)\n",
    "                tenure = int(tenure.days)\n",
    "\n",
    "            titles_temp = []\n",
    "            for film in person['films']:\n",
    "                titles_temp.append(film)\n",
    "                scores = []\n",
    "                if 'imdb_score' in titles_dict[film]['scores'] and pd.notnull(titles_dict[film]['scores']['imdb_score']):\n",
    "                    scores.append(float(titles_dict[film]['scores']['imdb_score'])*10)\n",
    "                for col in ['metascore', 'rt_critics', 'rt_users']:\n",
    "                    if col in titles_dict[film]['scores'] and pd.notnull(titles_dict[film]['scores'][col]):\n",
    "                        scores.append(float(titles_dict[film]['scores'][col]))\n",
    "\n",
    "            if 'director' in person['profession']:\n",
    "                directors[name] = {}\n",
    "                directors[name]['score'] = np.mean(scores)\n",
    "                directors[name]['gross'] = gross_temp\n",
    "                directors[name]['tenure'] = tenure\n",
    "                directors[name]['films'] = titles_temp\n",
    "                directors[name]['dates'] = pd.to_datetime(dates)\n",
    "\n",
    "            if 'actor' in person['profession']:\n",
    "                actors[name] = {}\n",
    "                actors[name]['score'] = np.mean(scores)\n",
    "                actors[name]['gross'] = gross_temp\n",
    "                actors[name]['tenure'] = tenure\n",
    "                actors[name]['films'] = titles_temp\n",
    "                actors[name]['dates'] = pd.to_datetime(dates)\n",
    "    except:\n",
    "        print person[\"name\"]\n",
    "#         print person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to check if people in db\n",
    "names = [person['name'] for person in people]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alanxie/anaconda/lib/python2.7/site-packages/numpy/lib/nanfunctions.py:703: RuntimeWarning: Mean of empty slice\n",
      "  warnings.warn(\"Mean of empty slice\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# to save film dates, to ensure that director/actor gross\n",
    "# only takes into account films before that film's release date\n",
    "\n",
    "films = {}\n",
    "for title in titles:\n",
    "    name = title['title']\n",
    "    films[name] = {}\n",
    "    films[name]['score'] = []\n",
    "    films[name]['gross'] = None\n",
    "    films[name]['release_date'] = None\n",
    "    if 'domestic_gross' in title and pd.notnull(title['domestic_gross']):\n",
    "        films[name]['gross'] = title['domestic_gross']\n",
    "    if 'theatrical_release' in title and pd.notnull(title['theatrical_release']):\n",
    "        if '$date' in title['theatrical_release'] and pd.notnull(title['theatrical_release']['$date']):\n",
    "                films[name]['release_date'] = pd.to_datetime(title['theatrical_release']['$date'])\n",
    "    if 'imdb_score' in title['scores'] and pd.notnull(title['scores']['imdb_score']):\n",
    "        films[name]['score'].append(float(title['scores']['imdb_score'])*10)\n",
    "    for col in ['metascore', 'rt_critics', 'rt_users']:\n",
    "        if col in title['scores'] and pd.notnull(title['scores'][col]):\n",
    "            films[name]['score'].append(float(title['scores'][col]))\n",
    "    films[name]['score'] = np.nanmean(films[name]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alanxie/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for title in titles:\n",
    "    if SELECT_FILMS == True:\n",
    "        if title['title'] not in SELECT_TITLES:\n",
    "            continue\n",
    "    flat = flatten(title)\n",
    "    actor_score_temp = []\n",
    "    direc_score_temp = []\n",
    "    actor_gross_temp = []\n",
    "    direc_gross_temp = []\n",
    "    actor_tenures_temp = []\n",
    "    direc_tenures_temp = []\n",
    "    if title['theatrical_release']:\n",
    "        release_date = pd.to_datetime(title['theatrical_release']['$date'])\n",
    "    # include actor and director scores by referencing them from their dicts\n",
    "    for actor in flat['actor']:\n",
    "        # checker for whether in person db\n",
    "        if actor in names:\n",
    "            # get mean score for actor using scores before current film, add to list\n",
    "            score = np.nanmean([films[film_title]['score'] for film_title in actors[actor]['films'] if films[film_title]['release_date'] is not None and films[film_title]['release_date'] < release_date])\n",
    "            actor_score_temp.append(score)\n",
    "            # get mean gross for actor using grosses before current film, add to list \n",
    "            gross = np.nanmean(filter(None, [films[film_title]['gross'] for film_title in actors[actor]['films'] if films[film_title]['release_date'] is not None and films[film_title]['release_date'] < release_date]))\n",
    "            actor_gross_temp.append(gross) \n",
    "            # create mean tenure for actor using dates before current film, add to list\n",
    "            if len(actors[actor]['dates']) > 0:\n",
    "                tenure_temp = (release_date - np.min(actors[actor]['dates'].values)).days\n",
    "                actor_tenures_temp.append(tenure_temp)\n",
    "            else:\n",
    "                actor_tenures_temp.append(0)\n",
    "    # handle the case of messed up actors\n",
    "    if not actor_tenures_temp:\n",
    "        actor_mean_tenure = 0\n",
    "        actor_stddev_tenure = 0\n",
    "    else:\n",
    "        actor_tenures_temp = np.array(actor_tenures_temp)\n",
    "        actor_mean_tenure = np.mean(actor_tenures_temp[actor_tenures_temp.nonzero()])\n",
    "        actor_stddev_tenure = np.std(actor_tenures_temp[actor_tenures_temp.nonzero()])\n",
    "    for director in flat['director']:\n",
    "        if director in names:\n",
    "            score = np.nanmean([films[film_title]['score'] for film_title in directors[director]['films'] if films[film_title]['release_date'] is not None and films[film_title]['release_date'] < release_date])\n",
    "            direc_score_temp.append(score)\n",
    "            gross = np.nanmean(filter(None, [films[film_title]['gross'] for film_title in directors[director]['films'] if films[film_title]['release_date'] is not None and films[film_title]['release_date'] < release_date]))\n",
    "            direc_gross_temp.append(gross)\n",
    "            if len(directors[director]['dates']) > 0:\n",
    "                tenure_temp = (release_date - np.min(directors[director]['dates'].values)).days\n",
    "                direc_tenures_temp.append(tenure_temp)\n",
    "            else:\n",
    "                direc_tenures_temp.append(0)\n",
    "    if not direc_tenures_temp:\n",
    "        direc_mean_tenure = 0\n",
    "    else:\n",
    "        direc_tenures_temp = np.array(direc_tenures_temp)\n",
    "        direc_mean_tenure = np.mean(direc_tenures_temp[direc_tenures_temp.nonzero()])\n",
    "        direc_stddev_tenure = np.std(direc_tenures_temp[direc_tenures_temp.nonzero()])\n",
    "    flat['actor_score'] = np.mean(actor_score_temp)\n",
    "    flat['director_score'] = np.mean(direc_score_temp)\n",
    "    flat['mean_actor_gross'] = np.mean(actor_gross_temp)\n",
    "    flat['mean_director_gross'] = np.mean(direc_gross_temp)\n",
    "    flat['actor_mean_tenure'] = actor_mean_tenure \n",
    "    flat['actor_stddev_tenure'] = actor_stddev_tenure\n",
    "    flat['direc_mean_tenure'] = direc_mean_tenure\n",
    "    flat['direc_stddev_tenure'] = direc_stddev_tenure\n",
    "    flat = pd.DataFrame(pd.Series(flat)).transpose()\n",
    "    dfs.append(flat)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def releaseDater(row, SELECT_DATES):\n",
    "    film_title = row['title']\n",
    "    select_dates = SELECT_DATES[film_title]\n",
    "    date_range = pd.date_range(start = select_dates[0], end = select_dates[1], freq = 'W')\n",
    "    new_rows = pd.concat([pd.DataFrame(row).T] * len(date_range))\n",
    "    new_rows['theatrical_release_$date'] = date_range\n",
    "    return new_rows\n",
    "\n",
    "if SELECT_FILMS == True:\n",
    "    df = pd.concat([releaseDater(x, SELECT_DATES) for _, x in list(df.iterrows())])\n",
    "    df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create release date features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2019-01-06\n",
       "1    2019-01-13\n",
       "2    2019-01-20\n",
       "3    2019-01-27\n",
       "4    2019-02-03\n",
       "5    2019-02-10\n",
       "6    2019-02-17\n",
       "7    2019-02-24\n",
       "8    2019-03-03\n",
       "9    2019-03-10\n",
       "10   2019-03-17\n",
       "11   2019-03-24\n",
       "12   2019-03-31\n",
       "13   2019-04-07\n",
       "14   2019-04-14\n",
       "15   2019-04-21\n",
       "16   2019-04-28\n",
       "17   2019-05-05\n",
       "18   2019-05-12\n",
       "19   2019-05-19\n",
       "20   2019-05-26\n",
       "21   2019-06-02\n",
       "22   2019-06-09\n",
       "23   2019-06-16\n",
       "24   2019-06-23\n",
       "25   2019-06-30\n",
       "26   2019-07-07\n",
       "27   2019-07-14\n",
       "28   2019-07-21\n",
       "29   2019-07-28\n",
       "30   2019-08-04\n",
       "31   2019-08-11\n",
       "32   2019-08-18\n",
       "33   2019-08-25\n",
       "34   2019-09-01\n",
       "35   2019-09-08\n",
       "36   2019-09-15\n",
       "37   2019-09-22\n",
       "38   2019-09-29\n",
       "39   2019-10-06\n",
       "40   2019-10-13\n",
       "41   2019-10-20\n",
       "42   2019-10-27\n",
       "43   2019-11-03\n",
       "44   2019-11-10\n",
       "45   2019-11-17\n",
       "46   2019-11-24\n",
       "47   2019-12-01\n",
       "48   2019-12-08\n",
       "49   2019-12-15\n",
       "50   2019-12-22\n",
       "51   2019-12-29\n",
       "Name: theatrical_release_$date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['theatrical_release_$date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['release_date'] = df['theatrical_release_$date']\n",
    "df['release_date'] = pd.to_datetime(df['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# takes in a film, returns mean_week_1, mean_domestic, # of preceding films\n",
    "def filmFranchiser(row, franchise_df):\n",
    "    rd = row['release_date']\n",
    "    title = row['title']\n",
    "    result = pd.Series({'days_since_last_entry': 0,\n",
    "                          'gross_prev_entry': 0,\n",
    "                          'mean_first_wknd_gross': 0,\n",
    "                          'mean_week_1_gross': 0,\n",
    "                          'mean_franchise_domestic_gross': 0,\n",
    "                          'num_preceding_films': 0})\n",
    "    franchise_check = franchise_df[franchise_df['film'] == row['title']]\n",
    "    if franchise_check.empty:\n",
    "        return result\n",
    "    else:\n",
    "        franchise = franchise_check['franchise'].values[0]\n",
    "        franchise_films = franchise_df[franchise_df['franchise'] == franchise]\n",
    "        prev_films = franchise_films[franchise_films['release_date'] < rd]\n",
    "        if prev_films.empty:\n",
    "            return result\n",
    "        else:\n",
    "            result['days_since_last_entry'] = (rd - np.max(prev_films['release_date'])).days\n",
    "            result['gross_prev_entry'] = np.max(prev_films.loc[prev_films['release_date'].idxmax()]['domestic_gross'])\n",
    "            result['mean_first_wknd_gross'] = np.mean(prev_films['first_wknd_gross'])\n",
    "            result['mean_week_1_gross'] = np.mean(prev_films['week_1_gross'])\n",
    "            result['mean_franchise_domestic_gross'] = np.mean(prev_films['domestic_gross'])\n",
    "            result['num_preceding_films'] = prev_films.shape[0]\n",
    "            return result\n",
    "        \n",
    "franchise_feats = df.apply(filmFranchiser, args = (franchise_df, ), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.merge(franchise_feats, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN THE FOLLOWING LINE OF CODE OR ALL FEATURES THAT RELY ON RELEASE DATE WILL BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "df['weekday'] = df['release_date'].dt.dayofweek\n",
    "df['week'] = df['release_date'].dt.weekofyear\n",
    "df['month'] = df['release_date'].dt.month\n",
    "df['year'] = df['release_date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cyclical pattern of films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_cycle = df[~pd.isnull(df['domestic_gross'])]\n",
    "# df_cycle = df_cycle[~pd.isnull(df_cycle['year'])]\n",
    "# df_cycle['domestic_gross'] = df_cycle['domestic_gross'].astype(int)\n",
    "# df_cycle = df_cycle[df_cycle['year'] > 1989]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy.optimize import leastsq\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# data = df_cycle.groupby(['year', 'month'])['domestic_gross'].mean()\n",
    "# N = len(data) # number of data points\n",
    "# t = np.linspace(0, 4* np.pi , N)\n",
    "\n",
    "# monthly_mean = np.mean(data)\n",
    "# monthly_std = 3*np.std(data)/(2**0.5)\n",
    "# monthly_phase = 0\n",
    "\n",
    "# # we'll use this to plot our first estimate. This might already be good enough for you\n",
    "# # data_first_guess = guess_std*np.sin(t+guess_phase) + guess_mean\n",
    "\n",
    "# # Define the function to optimize, in this case, we want to minimize the difference\n",
    "# # between the actual data and our \"guessed\" parameters\n",
    "# optimize_func = lambda x: x[0]*np.sin(t+x[1]) + x[2] - data\n",
    "# est_std, est_phase, est_mean = leastsq(optimize_func, [monthly_std, monthly_phase, monthly_mean])[0]\n",
    "\n",
    "# # recreate the fitted curve using the optimized parameters\n",
    "# data_fit = est_std*np.sin(t+est_phase) + est_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean_gross_monthly = data.reset_index().drop('domestic_gross', axis = 1)\n",
    "# mean_gross_monthly['cycle_pred'] = data_fit\n",
    "# df = df.merge(mean_gross_monthly, left_on = ['year', 'month'], right_on = ['year', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# d2 = pd.to_datetime('2016-01-01').to_datetime()\n",
    "# d1 = pd.to_datetime('1990-01-01').to_datetime()\n",
    "\n",
    "# (d1.year - d2.year)*12 + d1.month - d2.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# holiday distance variables\n",
    "# the big ones: washington's birthday, easter, memorial day, july 4,\n",
    "# labor day, thanksgiving, christmas, new years \n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "cal = calendar()\n",
    "\n",
    "def holCollect(date, cal):\n",
    "    distsDict = {}\n",
    "    for rule in cal.rules:\n",
    "        holidays = rule.dates(start_date = date - pd.DateOffset(months = 7), \n",
    "                              end_date = date + pd.DateOffset(months = 7))\n",
    "        # get the distance in days between each holiday and the date in question\n",
    "        dist = holDist(date,holidays)\n",
    "        distsDict[rule.name] = dist\n",
    "    return distsDict\n",
    "\n",
    "def holDist(date, holidays):\n",
    "    dists = [abs(date - holiday).days for holiday in holidays]\n",
    "    return np.min(dists)\n",
    "    \n",
    "hol_distances = df['release_date'].apply(lambda x: holCollect(x, cal) if pd.notnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hol_distances = hol_distances[hol_distances.notnull()].apply(lambda x: pd.Series(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hol_distances = hol_distances.apply(lambda array: array if type(array) == list and len(array) == 10 else [np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan])\n",
    "# hol_dists_to_save = pd.DataFrame(hol_dists_final, columns=['new_years', 'mlk_day', 'presidents_day', 'memorial_day',\n",
    "#                                      'jul_4th', 'labor_day', 'columbus_day', 'veterans_day',\n",
    "#                                      'thanksgiving_day', 'christmas_day'])\n",
    "# df = pd.concat([df, hol_dists_to_save], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.merge(hol_distances, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nunique franchises across actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nunique franchises across actors \n",
    "def nUniqueFranchises(row):\n",
    "    actors = row['actor']\n",
    "    release_date = row['release_date']\n",
    "    unique_prior_franchises = []\n",
    "    unique_prior_franchise_films = []\n",
    "    result = pd.Series({'unique_prior_franchises': 0,\n",
    "                        'unique_prior_franchise_films': 0})\n",
    "    for actor in actors:\n",
    "        prev_films = df[df['franchise'] != False]\n",
    "        if prev_films.empty:\n",
    "            continue\n",
    "        prev_films = prev_films[prev_films['release_date'] < release_date]\n",
    "        if prev_films.empty:\n",
    "            continue\n",
    "        prev_films = prev_films[prev_films['actor'].apply(lambda x: actor in x)]\n",
    "        if prev_films.empty:\n",
    "            continue\n",
    "        unique_prior_franchises.extend(prev_films['franchise'].tolist())\n",
    "        unique_prior_franchise_films.extend(prev_films['title'].tolist())\n",
    "    result['unique_prior_franchises'] = len(set(unique_prior_franchises))\n",
    "    result['unique_prior_franchise_films'] = len(set(unique_prior_franchise_films))\n",
    "    return result\n",
    "    \n",
    "n_unique_franchises = df.apply(nUniqueFranchises, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.merge(n_unique_franchises, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add personal disposable spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def nearestDate(dates, pivot, personal_spending):\n",
    "#     try: \n",
    "#         date = min(dates, key=lambda x: abs(x - pivot))\n",
    "#         return personal_spending[date]\n",
    "#     except:\n",
    "#         return np.nan\n",
    "\n",
    "# personal_spending = pd.read_csv('personal_spending.csv')\n",
    "# personal_spending = dict(zip(pd.to_datetime((personal_spending['DATE'])), personal_spending['DSPIC96']))\n",
    "# spend_dates = pd.to_datetime(personal_spending.keys())\n",
    "# df['personal_spending'] = df['release_date'].apply(lambda x : nearestDate(spend_dates, x, personal_spending))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get number of films released in same week and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['competition_week'] = df['release_date'].apply(lambda x: len(df[(df['release_date'] > x - pd.DateOffset(4)) & \n",
    "                                                                   (df['release_date'] < x + pd.DateOffset(4))]) - 1)\n",
    "\n",
    "df['competition_month'] = df['release_date'].apply(lambda x: len(df[(df['release_date'] > x - pd.DateOffset(15)) & \n",
    "                                                                   (df['release_date'] < x + pd.DateOffset(15))]) - 1)\n",
    "df['competition_week'].replace(-1, np.nanmean(df['competition_week'].replace(-1, np.nan)), inplace = True)\n",
    "df['competition_month'].replace(-1, np.nanmean(df['competition_month'].replace(-1, np.nan)), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix types, missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['franchise'] = df['franchise'].astype(bool)\n",
    "df['mean_director_gross'] = df['mean_director_gross'].astype(float)\n",
    "df['mean_actor_gross'] = df['mean_actor_gross'].astype(float)\n",
    "df['director_score'] = df['director_score'].astype(float)\n",
    "df['actor_score'] = df['actor_score'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix missing runtimes\n",
    "df['runtime'] = df['runtime'].replace('', 0)\n",
    "df['runtime'] = df['runtime'].astype(int)\n",
    "df['runtime'] = df['runtime'].replace(0, np.nan)\n",
    "\n",
    "# replace NaN tenures with 0's\n",
    "df['actor_mean_tenure'] = df['actor_mean_tenure'].fillna(0)\n",
    "df['direc_mean_tenure'] = df['direc_mean_tenure'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # strips whitespace in strings within list of variable sublist size recursively\n",
    "# def genre_retrieval(multilist):\n",
    "#     newlist = []\n",
    "#     for x in multilist:\n",
    "#         type_x = type(x)\n",
    "#         if type_x == list:\n",
    "#             newlist.append([item for item in genre_retrieval(x)])\n",
    "#         elif type_x == str or type_x == unicode:\n",
    "#             x = x.strip()\n",
    "#             newlist.append(x)\n",
    "#     return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all unique genres\n",
    "genres = pd.Series([val.strip() for sublist in df.genres.dropna().tolist() for val in sublist]).unique()\n",
    "\n",
    "# init series\n",
    "for genre in genres:\n",
    "    df[genre] = 0\n",
    "df['genres'] = df['genres'].fillna('N/A')\n",
    "\n",
    "# replace error with NA for each movie \n",
    "listed = df['genres'].tolist()\n",
    "for i in range(len(listed)):\n",
    "    if listed[i] == 'N/A':\n",
    "        listed[i] = ['N/A']\n",
    "df['genres'] = listed\n",
    "\n",
    "final_genres_list = []\n",
    "for sublist in df.genres.tolist():\n",
    "    sublist_temp = []\n",
    "    for string in sublist:\n",
    "        sublist_temp.append(string.strip())\n",
    "    final_genres_list.append(sublist_temp)\n",
    "\n",
    "df['genres'] = final_genres_list\n",
    "\n",
    "for i in range(len(df)):\n",
    "    for genre in df.genres.iat[i]:\n",
    "        df[genre].iat[i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mean gross by genre for previous year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df[df['domestic_gross'].apply(lambda x: type(x) != int)][['title', 'domestic_gross']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_gross_genre(film):\n",
    "    mean_grosses = []\n",
    "    lastyear = df[df['year'] == film['year'] - 1]\n",
    "    for genre in film['genres']:\n",
    "        try: \n",
    "            mean_grosses.append(np.mean(lastyear[lastyear[genre] == 1]['domestic_gross'].dropna()))\n",
    "        except:\n",
    "            print df.keys()\n",
    "            mean_grosses.append(np.mean(df[df[genre] == 1]['domestic_gross'].dropna()))\n",
    "    return np.nanmean(mean_grosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['mean_gross_by_genre_prev_year'] = df.apply(lambda x: mean_gross_genre(x), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean director genre expertise (mean number of times directors have starred in a movie of that genre before this movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def mean_direc_genre_expertise(title):\n",
    "#     if title['theatrical_release']:\n",
    "#         release = title['theatrical_release']['$date']\n",
    "#         genre = title['genres'][0]\n",
    "#         counts = []\n",
    "#         for direc in title['director']:\n",
    "#             films = df[df['director'].apply(lambda x: direc in x)]\n",
    "#             films = films[films['theatrical_release_$date'].apply(lambda x: pd.notnull(x))]\n",
    "#             films = films[films['theatrical_release_$date'].apply(lambda x: x < release)]\n",
    "#             films = films[films['genres'].apply(lambda x: genre in x)]\n",
    "#             if films.empty:\n",
    "#                 counts.append(np.nan)\n",
    "#             else:\n",
    "#                 counts.append(len(films))\n",
    "#         return np.nanmean(counts)\n",
    "#     else:\n",
    "#         return np.nan\n",
    "    \n",
    "# df['mean_direc_genre_expertise'] = [mean_direc_genre_expertise(title) for title in titles]\n",
    "# df['mean_direc_genre_expertise'] = df['mean_direc_genre_expertise'].fillna(df['mean_direc_genre_expertise'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean actor genre expertise (mean number of times actors have starred in a movie of that genre before this movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def mean_act_genre_expertise(title):\n",
    "#     if title['theatrical_release']:\n",
    "#         release = title['theatrical_release']['$date']\n",
    "#         genre = title['genres'][0]\n",
    "#         counts = []\n",
    "#         for act in title['actor']:\n",
    "#             films = df[df['actor'].apply(lambda x: act in x)]\n",
    "#             films = films[films['theatrical_release_$date'].apply(lambda x: pd.notnull(x))]\n",
    "#             films = films[films['theatrical_release_$date'].apply(lambda x: x < release)]\n",
    "#             films = films[films['genres'].apply(lambda x: genre in x)]\n",
    "#             if films.empty:\n",
    "#                 counts.append(np.nan)\n",
    "#             else:\n",
    "#                 counts.append(len(films))\n",
    "#         return np.nanmean(counts)\n",
    "#     else:\n",
    "#         return np.nan\n",
    "    \n",
    "# df['mean_act_genre_expertise'] = [mean_act_genre_expertise(title) for title in titles]\n",
    "# df['mean_act_genre_expertise'] = df['mean_act_genre_expertise'].fillna(df['mean_act_genre_expertise'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mean director gross by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_direc_gross_genre(title_of_movie):\n",
    "    title = titles_dict[title_of_movie]\n",
    "    if title['theatrical_release']:\n",
    "        release = pd.to_datetime(title['theatrical_release']['$date'])\n",
    "        genre = title['genres'][0]\n",
    "        grosses = []\n",
    "        for direc in title['director']:\n",
    "            films = df[df['director'].apply(lambda x: direc in x)]\n",
    "            if films.empty:\n",
    "                grosses.append(np.nan)\n",
    "                continue\n",
    "            films = films[films['release_date'].apply(lambda x: pd.notnull(x))]\n",
    "            films = films[films['release_date'].apply(lambda x: x < release)]\n",
    "            films = films[films['genres'].apply(lambda x: genre in x)]\n",
    "            if films.empty:\n",
    "                grosses.append(np.nan)\n",
    "            else:\n",
    "                films = films[films['domestic_gross'].apply(lambda x: pd.notnull(x))]\n",
    "                grosses.append(np.nanmean(films['domestic_gross']))\n",
    "        return np.nanmean(grosses)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['mean_direc_gross_genre'] = Parallel(n_jobs=4)(delayed(mean_direc_gross_genre)(title_of_movie) for title_of_movie in df['title'].tolist())\n",
    "df['mean_direc_gross_genre'] = df['mean_direc_gross_genre'].fillna(df['mean_direc_gross_genre'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mean actor gross by genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_act_gross_genre(title_of_movie):\n",
    "    title = titles_dict[title_of_movie]\n",
    "    if title['theatrical_release']:\n",
    "        release = pd.to_datetime(title['theatrical_release']['$date'])\n",
    "        genre = title['genres'][0]\n",
    "        grosses = []\n",
    "        for act in title['actor']:\n",
    "            films = df[df['actor'].apply(lambda x: act in x)]\n",
    "            films = films[films['release_date'].apply(lambda x: pd.notnull(x))]\n",
    "            films = films[films['release_date'].apply(lambda x: x < release)]\n",
    "            films = films[films['genres'].apply(lambda x: genre in x)]\n",
    "            if films.empty:\n",
    "                grosses.append(np.nan)\n",
    "            else:\n",
    "                films = films[films['domestic_gross'].apply(lambda x: pd.notnull(x))]\n",
    "                grosses.append(np.nanmean(films['domestic_gross']))\n",
    "        return np.nanmean(grosses)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['mean_act_gross_genre'] = Parallel(n_jobs=4)(delayed(mean_act_gross_genre)(title_of_movie) for title_of_movie in df['title'].tolist())\n",
    "df['mean_act_gross_genre'] = df['mean_act_gross_genre'].fillna(df['mean_act_gross_genre'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean actor-director collaboration frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean_act_direc_collab_freq(title_of_movie):\n",
    "    title = titles_dict[title_of_movie]\n",
    "    if title['theatrical_release']:\n",
    "        release = pd.to_datetime(title['theatrical_release']['$date'])\n",
    "        collabs = []\n",
    "        for act in title['actor']:\n",
    "            act_collabs = []\n",
    "            for direc in title['director']:\n",
    "                films = df[df['director'].apply(lambda x: direc in x)]\n",
    "                films = films[films['release_date'].apply(lambda x: pd.notnull(x))]\n",
    "                films = films[films['release_date'].apply(lambda x: x < release)]\n",
    "                films = films[films['actor'].apply(lambda x: act in x)]\n",
    "                if films.empty:\n",
    "                    act_collabs.append(0)\n",
    "                else:\n",
    "                    act_collabs.append(len(films))\n",
    "            collabs.append(np.nanmean(act_collabs))\n",
    "        return np.nanmean(collabs)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['mean_act_direc_collab_freq'] = Parallel(n_jobs=4)(delayed(mean_act_direc_collab_freq)(title_of_movie) for title_of_movie in df['title'].tolist())\n",
    "df['mean_act_direc_collab_freq'] = df['mean_act_direc_collab_freq'].fillna(df['mean_act_direc_collab_freq'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distributor production company collab freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def distributorProdcoCollabFreq(title_of_movie):\n",
    "    title = titles_dict[title_of_movie]\n",
    "    if title['theatrical_release']:\n",
    "        release = pd.to_datetime(title['theatrical_release']['$date'])\n",
    "        collabs = []\n",
    "        for distrib_co in title['distribution_co']:\n",
    "            distrib_cos_collabs = []\n",
    "            for prod_co in title['production_co']:\n",
    "                films = df[df['production_co'].apply(lambda x: prod_co in x)]\n",
    "                films = films[films['release_date'].apply(lambda x: pd.notnull(x))]\n",
    "                films = films[films['release_date'].apply(lambda x: x < release)]\n",
    "                films = films[films['distribution_co'].apply(lambda x: distrib_co in x)]\n",
    "                if films.empty:\n",
    "                    distrib_cos_collabs.append(0)\n",
    "                else:\n",
    "                    distrib_cos_collabs.append(len(films))\n",
    "            collabs.append(np.nanmean(distrib_cos_collabs))\n",
    "        return np.nanmean(collabs)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "df['mean_distrib_prodco_collab_freq'] = Parallel(n_jobs=4)(delayed(distributorProdcoCollabFreq)(title_of_movie) for title_of_movie in df['title'].tolist())\n",
    "df['mean_distrib_prodco_collab_freq'] = df['mean_distrib_prodco_collab_freq'].fillna(df['mean_distrib_prodco_collab_freq'].median())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in-genre competition during the week of the film's release: count, budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def igcPrevFollow(row):\n",
    "    release_date = row['release_date']\n",
    "    top_genre = row['genres'][0]\n",
    "    igcw_prev_week = df[(df['release_date'] >= release_date - pd.DateOffset(8)) & \n",
    "                        (df['release_date'] < release_date) &\n",
    "                        (df['genres'].apply(lambda x: top_genre in x))]\n",
    "    igcw_following_week = df[(df['release_date'] <= release_date + pd.DateOffset(8)) & \n",
    "                             (df['release_date'] > release_date) &\n",
    "                             (df['genres'].apply(lambda x: top_genre in x))]\n",
    "    igc_prev_wk = igcw_prev_week.shape[0]\n",
    "    igc_following_wk = igcw_following_week.shape[0]\n",
    "    igc_prev_wk_budgets = igcw_prev_week['production_budget'].mean()\n",
    "    igc_prev_wk_first_wknds = igcw_prev_week['first_wknd_gross'].mean()\n",
    "    igc_following_wk_budgets = igcw_following_week['production_budget'].mean()\n",
    "    result = pd.Series({'in_genre_competition_prev_week': igc_prev_wk,\n",
    "                       'in_genre_competition_following_week': igc_following_wk,\n",
    "                        'in_genre_competition_prev_wk_grosses': np.nanmax([igc_prev_wk_first_wknds, 0]),\n",
    "                       'in_genre_competition_budgets_prev_week': np.nanmax([igc_prev_wk_budgets, 0]),\n",
    "                        'in_genre_competition_budgets_following_week': np.nanmax([igc_following_wk_budgets, 0])})\n",
    "    return result\n",
    "\n",
    "\n",
    "igc_feats = df.apply(igcPrevFollow, axis = 1)\n",
    "df = df.merge(igc_feats, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean, stddev, count of films previously released by distcos, prodcos, writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def aggPrevFilms(df, colname, entities, release_date, min_film_count, result):\n",
    "    if len(entities) > 0:\n",
    "        for entity in entities:\n",
    "            prev_grosses = []\n",
    "            prev_films = df[(df[colname].apply(lambda x: entity in x)) &\n",
    "                  (df['release_date'] < release_date)]\n",
    "            if not prev_films.empty:\n",
    "                prev_films = prev_films[['domestic_gross', 'title']]\n",
    "                prev_grosses.append(prev_films)\n",
    "        if len(prev_grosses) > min_film_count:\n",
    "            prev_grosses = pd.concat(prev_grosses).drop_duplicates()\n",
    "            result[colname + '_mean_gross'] = prev_grosses['domestic_gross'].mean()\n",
    "            result[colname + '_stddev_gross'] = prev_grosses['domestic_gross'].std()\n",
    "            result[colname + '_prev_count'] = prev_grosses['title'].nunique()\n",
    "    return result\n",
    "\n",
    "def distProdWriterFeats(row, df):\n",
    "    release_date = row['release_date']\n",
    "    # get the number of previous films by distco involved\n",
    "    # filter out distcos with < 5 films released\n",
    "    dist_cos = row['distribution_co']\n",
    "    prod_cos = row['production_co']\n",
    "    writers = row['screenwriter']\n",
    "    result = pd.Series({'distribution_co_mean_gross': 0,\n",
    "                        'distribution_co_stddev_gross':0,\n",
    "                        'distribution_co_prev_count':0,\n",
    "                        'production_co_mean_gross':0,\n",
    "                        'production_co_stddev_gross':0,\n",
    "                        'production_co_prev_count':0,\n",
    "                        'screenwriter_mean_gross':0,\n",
    "                        'screenwriter_stddev_gross':0,\n",
    "                        'screenwriter_prev_count':0})\n",
    "    result = aggPrevFilms(df, 'distribution_co', dist_cos, release_date, 0, result)\n",
    "    result = aggPrevFilms(df, 'production_co', prod_cos, release_date, 0, result)\n",
    "    result = aggPrevFilms(df, 'screenwriter', writers, release_date, 0, result)\n",
    "    return result.fillna(0)\n",
    "\n",
    "distco_prodco_writer_feats = df.apply(distProdWriterFeats, args = (df,), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.merge(distco_prodco_writer_feats, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentage of production studios previous films that are franchises / adaptations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prevProdCoFranchisesAdpts(row, df):\n",
    "    release_date = row['release_date']\n",
    "    # get the number of previous films by prod cos involved\n",
    "    prod_cos = row['production_co']\n",
    "    result = pd.Series({'prod_co_prev_franchise_films':0.0,\n",
    "                        'prod_co_prev_adpts': 0.0})\n",
    "    if prod_cos != []:\n",
    "        prod_co_percent_franchises = []\n",
    "        prod_co_percent_adpts = []\n",
    "        for prod_co in prod_cos:\n",
    "            prev_films = df[(df['production_co'].apply(lambda x: prod_co in x)) &\n",
    "                  (df['release_date'] < release_date)]\n",
    "            if not prev_films.empty:\n",
    "                prev_films = prev_films[['franchise', 'adaptation', 'title']]\n",
    "                num_prev = float(prev_films.shape[0])\n",
    "                if num_prev > 0:\n",
    "                    num_franch = prev_films.franchise.apply(lambda x: x in (True, 1, 'True')).sum()\n",
    "                    num_adpt = prev_films.adaptation.apply(lambda x: x not in (False, 'False')).sum()\n",
    "                    prod_co_percent_franchises.append(num_franch / num_prev)\n",
    "                    prod_co_percent_adpts.append(num_adpt / num_prev)\n",
    "        if len(prod_co_percent_franchises) > 1:\n",
    "            result['prod_co_prev_franchise_films'] = np.nanmean(prod_co_percent_franchises)\n",
    "        if len(prod_co_percent_adpts) > 1:\n",
    "            result['prod_co_prev_adpts'] = np.nanmean(prod_co_percent_adpts)\n",
    "    return result\n",
    "\n",
    "prodco_franch_adpt_feats = df.apply(prevProdCoFranchisesAdpts, args = (df,), axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.merge(prodco_franch_adpt_feats, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# efficiency of career: mean across actors of (tenure / age) * log(mean_gross)\n",
    "\n",
    "def ageFeatFunc(row):\n",
    "    release_date = row['release_date']\n",
    "    # get the number of previous films by writers involved\n",
    "    # filter out writers with < 3 films written\n",
    "    actors = row['actor']\n",
    "    film_title = row['title']\n",
    "    result = pd.Series({'actors_mean_age':0,\n",
    "                          'actors_max_age':0,\n",
    "                          'actors_stddev_age':0.0,\n",
    "                          'career_efficiency':0.0})\n",
    "    if actors == []:\n",
    "        return result\n",
    "    if pd.isnull(release_date):\n",
    "        return result\n",
    "    else:\n",
    "        ages = []\n",
    "        efficiencies = []\n",
    "        for actor in actors:\n",
    "            try:\n",
    "                if pd.isnull(people_dict[actor]['birthday']['$date']):\n",
    "                    continue\n",
    "            except:\n",
    "                continue\n",
    "            bday = pd.to_datetime(people_dict[actor]['birthday']['$date'])\n",
    "            age = (release_date - bday).days\n",
    "            ages.append(age)\n",
    "            prev_films = df[(df['release_date'] < release_date) &\n",
    "                            (df['title'].apply(lambda x: x in people_dict[actor]['films']))]\n",
    "            if not prev_films.empty:\n",
    "                prev_films = prev_films[['domestic_gross', 'release_date']]\n",
    "                prev_films['release_date'] = pd.to_datetime(prev_films['release_date'])\n",
    "                tenure = (release_date - prev_films['release_date'].min()).days\n",
    "                mean_gross = prev_films['domestic_gross'].mean()\n",
    "                efficiency = (tenure / float(age)) * np.nanmax((np.log(mean_gross), 0))\n",
    "                efficiencies.append(efficiency)\n",
    "        if len(ages) < 1:\n",
    "            return result\n",
    "        else:\n",
    "            result['actors_mean_age'] = np.mean(ages)\n",
    "            result['actors_max_age'] = np.max(ages)\n",
    "            result['actors_stddev_age'] = np.std(ages)\n",
    "            result['career_efficiency'] = np.nanmax((np.nanmean(efficiencies), 0))\n",
    "            return result\n",
    "\n",
    "result = pd.DataFrame(Parallel(n_jobs=4)(delayed(ageFeatFunc)(row) for _, row in list(df.iterrows())))\n",
    "df = df.merge(result, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversity related features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def typecastScore(all_films):\n",
    "    typecast_scores = []\n",
    "    for actor_list in all_films:\n",
    "        if len(actor_list) > 0:\n",
    "            races = [people_dict[actor]['race'] for actor in actor_list if actor in people_dict and 'race' in people_dict[actor]]\n",
    "            if len(races) > 0:\n",
    "                typecast_score = 0\n",
    "                races = Counter(races)\n",
    "                count_sum = float(sum(races.values()))\n",
    "                for key in races.keys():\n",
    "                    races[key] = races[key] / count_sum\n",
    "                if 'White' in races and races['White'] <= .5:\n",
    "                    typecast_score = 1.0\n",
    "                typecast_scores.append(typecast_score)\n",
    "    return np.nanmean(typecast_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def diversityFeats(row):\n",
    "    actors = row['actor']\n",
    "    directors = row['director']\n",
    "    release_date = row['release_date']\n",
    "    nunique_races = 0\n",
    "    percent_white = 100\n",
    "    percent_male = .6\n",
    "    director_white = True\n",
    "    director_male = True\n",
    "    mean_typecast_score = .5\n",
    "    typecast_scores = []\n",
    "    if len(actors) > 0:\n",
    "        act_races = []\n",
    "        act_genders = []\n",
    "        for actor in actors:\n",
    "            if actor in people_dict:\n",
    "                if 'race' in people_dict[actor]:\n",
    "                    act_races.append(people_dict[actor]['race'])\n",
    "                    # for all prev films, a 0 or 1 for whether majority race is nonwhite\n",
    "                    # mean across prev films \n",
    "                    prev_films = df[(df['release_date'] < release_date) &\n",
    "                                (df['title'].apply(lambda x: x in people_dict[actor]['films']))]['actor']\n",
    "                    if not prev_films.empty:\n",
    "                        typecast_score = typecastScore(prev_films.tolist())\n",
    "                        typecast_scores.append(typecast_score)\n",
    "                if 'gender' in people_dict[actor]:\n",
    "                    act_genders.append(people_dict[actor]['gender'])\n",
    "        if len(act_races) > 0:\n",
    "            nunique_races = len(set(act_races))\n",
    "            percent_white = len([ele for ele in act_races if ele == 'White']) / float(len(act_races))\n",
    "        if len(act_genders) > 0:\n",
    "            percent_male = len([ele for ele in act_genders if ele == 'Male']) / float(len(act_genders))\n",
    "    if len(directors) > 0:\n",
    "        direc_races = []\n",
    "        direc_genders = []\n",
    "        for director in directors:\n",
    "            if 'race' in people_dict[director]:\n",
    "                direc_races.append(people_dict[director]['race'])\n",
    "            if 'gender' in people_dict[director]:\n",
    "                direc_genders.append(people_dict[director]['gender'])\n",
    "        direc_races_counter = Counter(direc_races)\n",
    "        direc_genders_counter = Counter(direc_genders)\n",
    "        if 'Male' not in direc_genders_counter:\n",
    "            director_male = False\n",
    "        if 'Female' in direc_genders_counter and 'Male' in direc_genders_counter:\n",
    "            if direc_genders_counter['Female'] > direc_genders_counter['Male']:\n",
    "                director_male = False\n",
    "        if 'White' not in direc_races_counter:\n",
    "            director_white = False\n",
    "        if len(direc_races_counter) > 1:\n",
    "            director_white = False\n",
    "    if len(typecast_scores) > 0:\n",
    "        typecast_scores = [score for score in typecast_scores if pd.notnull(score)]\n",
    "        mean_typecast_score = np.nanmean(typecast_scores)\n",
    "        \n",
    "    return pd.Series({'nunique_races': nunique_races,\n",
    "                      'percent_white': percent_white,\n",
    "                      'percent_male': percent_male,\n",
    "                      'director_white': director_white,\n",
    "                      'director_male': director_male,\n",
    "                      'typecast_score': mean_typecast_score})\n",
    "\n",
    "\n",
    "result = pd.DataFrame(Parallel(n_jobs=4)(delayed(diversityFeats)(row) for _, row in list(df.iterrows())))\n",
    "df = df.merge(result, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop bad columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'international_gross_$numberLong' in df.columns:\n",
    "    df = df.drop('international_gross_$numberLong', axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if SELECT_FILMS == True:\n",
    "    df.to_csv('df_release_dating.csv', index = False, encoding = 'utf-8')\n",
    "else:\n",
    "    df.to_csv('df_regr.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Intensive Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if SELECT_FILMS == True:\n",
    "    df = pd.read_csv('df_release_dating.csv')\n",
    "else:\n",
    "    df = pd.read_csv('df_regr.csv')\n",
    "# though genres and actors are lists originally, they're then stored as strings \n",
    "# this line changes them back\n",
    "for col in ['genres', 'actor', 'director', 'production_co', 'distribution_co']:\n",
    "    df[col] = df[col].apply(lambda x: [ele.strip() for ele in x[1:-1].split(',')])\n",
    "df['release_date'] = pd.to_datetime(df['release_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### average genre expertise (AGE), weighted AGE and cast novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if running this notebook top to bottom, genres is already defined, \n",
    "# if not, here they are \n",
    "genres = list(set(gen for sublist in df['genres'].tolist() for gen in sublist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for each film, for each actor in it\n",
    "# AGE: across-actor mean of genres vector multiplied by the proportion of the number of times \n",
    "# the actor previously starred in films of genres of the given film\n",
    "# WAGE: AGE weighted by gross\n",
    "# cast novelty: log gross / WAGE\n",
    "\n",
    "def AGE_WAGE_NOVELTY(idx, row):\n",
    "    # get actors involved\n",
    "    actors = row['actor']\n",
    "    # handle no actors \n",
    "    if actors == []:\n",
    "        return pd.Series({'average_genre_expertise': 0,\n",
    "                          'std_genre_expertise': 0,\n",
    "                          'weighted_average_genre_expertise': 0,\n",
    "                          'std_weighted_average_genre_expertise': 0,\n",
    "                          'cast_novelty': 0})\n",
    "    else:\n",
    "        # init vars \n",
    "        release_date = row['release_date']\n",
    "        film_gen_dict = {genre: 0 for genre in genres}\n",
    "        for genre in row['genres']:\n",
    "            film_gen_dict[genre] += 1\n",
    "        AGEs = []\n",
    "        WAGEs = []\n",
    "        cast_novelties = []\n",
    "        for actor in actors:\n",
    "            # get previous films by actors involved\n",
    "            prev_films = df[(df['release_date'] < release_date) &\n",
    "                (df['actor'].apply(lambda x: actor in x))]\n",
    "            if not prev_films.empty:\n",
    "                prev_films = prev_films[['domestic_gross', 'genres']]\n",
    "                # for each actor, gen vec * experience vec \n",
    "                actor_gen_dict = {genre: 0 for genre in genres}\n",
    "                # collect genres of previous films\n",
    "                prev_gens = [gen for sublist in prev_films['genres'].tolist() for gen in sublist]\n",
    "                for genre in prev_gens:\n",
    "                    actor_gen_dict[genre] += 1\n",
    "                # calculate normalizd AGE dict\n",
    "                factor=1.0/sum(actor_gen_dict.itervalues())\n",
    "                normalized_actor_gen_dict = {k: v*factor for k, v in actor_gen_dict.iteritems() }\n",
    "                # calculate AGE \n",
    "                AGE = sum(film_gen_dict[key]*normalized_actor_gen_dict.get(key, 0) for key in film_gen_dict)\n",
    "                AGEs.append(AGE)\n",
    "                # calculate WAGE\n",
    "                log_gross = np.log(prev_films['domestic_gross'].sum())\n",
    "                WAGEs.append(log_gross * AGE)\n",
    "                # calculate novelty\n",
    "                cast_novelties.append(log_gross / (AGE + 1))\n",
    "        mAGEs = 0\n",
    "        stdAGEs = 0\n",
    "        mWAGEs = 0\n",
    "        stdWAGEs = 0\n",
    "        max_cast_novelties = 0\n",
    "        if len(AGEs) > 0:\n",
    "            mAGEs = np.mean(AGEs)\n",
    "            stdAGEs = np.std(AGEs)\n",
    "        if len(WAGEs) > 0:\n",
    "            mWAGEs = np.mean(WAGEs)\n",
    "            stdWAGEs = np.std(WAGEs)\n",
    "        if len(cast_novelties) > 0:\n",
    "            max_cast_novelties = np.max(cast_novelties)\n",
    "        return pd.Series({'average_genre_expertise': mAGEs,\n",
    "                          'std_genre_expertise': stdAGEs,\n",
    "                          'weighted_average_genre_expertise': mWAGEs,\n",
    "                          'std_weighted_average_genre_expertise': stdWAGEs,\n",
    "                          'cast_novelty': max_cast_novelties})\n",
    "    \n",
    "result = Parallel(n_jobs=4)(delayed(AGE_WAGE_NOVELTY)(idx, row) for idx, row in list(df.iterrows()))\n",
    "df = df.merge(pd.DataFrame(result), how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if SELECT_FILMS == True:\n",
    "    df.to_csv('df_release_dating.csv', index = False, encoding = 'utf-8')\n",
    "else:\n",
    "    df.to_csv('df_regr.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning out duplicate people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from fuzzywuzzy import fuzz\n",
    "# names1 = [person['name'].lower() for person in people]\n",
    "# dupe_suggestions = []\n",
    "# seen_names = []\n",
    "# for name1 in names1:\n",
    "#     seen_names.append(name1)\n",
    "#     names2 = names1[:]\n",
    "#     for seen_name in seen_names:\n",
    "#         names2.remove(seen_name)\n",
    "#     overlap_ratio = np.array([fuzz.token_set_ratio(name1, name2) for name2 in names2])\n",
    "#     if any(overlap_ratio > 90):\n",
    "#         max_overlap_ratio_idxs = overlap_ratio.argsort()[-3:][::-1]\n",
    "#         dupe_suggestions.append({name1:np.take(names2,max_overlap_ratio_idxs)})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
